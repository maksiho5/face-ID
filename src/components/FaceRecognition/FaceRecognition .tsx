import { useEffect, useState, useRef } from "react";
import * as faceapi from "face-api.js";
import { log } from "console";

const labels = [
    "–î–∂–µ—Ä–µ–º–∏ –†–µ–Ω–Ω–µ—Ä",
    "–î–º–∏—Ç—Ä–∏–π –ù–∞–∑–∞—Ä–æ–≤",
    "–î–æ—Ä–∏–∞–Ω –•—ç—Ä–≤—É–¥",
    "–î—É—ç–π–Ω –î–∂–æ–Ω—Å–æ–Ω",
    "–ö—Ä–∏—Å –•–µ–º—Å–≤–æ—Ä—Ç",
    "–ö—Ä–∏—Å –≠–≤–∞–Ω—Å",
    "–ö—ç—Ä–æ–ª –î—ç–Ω–≤–µ—Ä—Å",
    "–†–æ–±–µ—Ä—Ç –î–∞—É–Ω–∏-–º–ª–∞–¥—à–∏–π",
    "–°–∫–∞—Ä–ª–µ—Ç—Ç –ô–æ—Ö–∞–Ω—Å—Å–æ–Ω",
    "C–µ—Ä–≥–µ–π –ë–µ–∑—Ä—É–∫–æ–≤"
];

function FaceRecognition() {
    const [modelsLoaded, setModelsLoaded] = useState(false);
    const [labeledFaceDescriptors, setLabeledFaceDescriptors] = useState(null);
    const [selectedFile, setSelectedFile] = useState(null);
    const [imagePreview, setImagePreview] = useState(null);
    const [matchResults, setMatchResults] = useState([]);
    const imageRef = useRef(null);
    const canvasRef = useRef(null);

    // üìå –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏ FaceAPI.js
    useEffect(() => {
        const loadModels = async () => {
            const MODEL_URL = "/models";
            await Promise.all([
                faceapi.nets.ssdMobilenetv1.loadFromUri(MODEL_URL),
                faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),
                faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),
            ]);
            setModelsLoaded(true);
        };
        loadModels();
    }, []);

    // üìå –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—É—á–µ–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≥–µ—Ä–æ–µ–≤ Marvel (—Å –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞)
    useEffect(() => {
        if (!modelsLoaded) return;

        const loadLabeledImages = async () => {
            return Promise.all(
                labels.map(async (label) => {
                    const descriptions = [];
                    // –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–æ—Ä–º–∞—Ç–æ–≤: jpg –∏ png
                    for (let i = 1; i <= 2; i++) {
                        try {
                            const imgUrls = [
                                `https://192.168.0.113:3000/labeled_images/${label}/${i}.jpg`,
                                `https://192.168.0.113:3000/labeled_images/${label}/${i}.png`,
                            ];

                            for (const imgUrl of imgUrls) {
                                try {
                                    const img = await faceapi.fetchImage(imgUrl);
                                    const detections = await faceapi
                                        .detectSingleFace(img)
                                        .withFaceLandmarks()
                                        .withFaceDescriptor();
                                    if (detections) descriptions.push(detections.descriptor);
                                    break; // –ï—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–æ –∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ, –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞
                                } catch (err) {
                                    console.log(`–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ${imgUrl}:`, err);
                                }
                            }
                        } catch (e) {
                            console.log(e);

                        }

                    }
                    return new faceapi.LabeledFaceDescriptors(label, descriptions);
                })
            );
        };

        loadLabeledImages().then(setLabeledFaceDescriptors);
    }, [modelsLoaded]);

    // üìå –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –Ω–æ–≤–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    const handleFileChange = (event) => {

        try {
            const file = event.target.files[0];


            setSelectedFile(file);
            setImagePreview(URL.createObjectURL(file));
            setMatchResults([]); // –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

            // –û—á–∏—â–∞–µ–º —Ö–æ–ª—Å—Ç –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π –Ω–æ–≤–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            if (canvasRef.current) {
                const ctx = canvasRef.current.getContext("2d");
                ctx.clearRect(0, 0, canvasRef.current.width, canvasRef.current.height);
            }
        } catch (e) {
            console.log(e);

        }

    };

    const recognizeFaces = async () => {

        try {
            if (!selectedFile ) return alert("–ó–∞–≥—Ä—É–∑–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ!");

            const img = await faceapi.bufferToImage(selectedFile);
            const faceMatcher = new faceapi.FaceMatcher(labeledFaceDescriptors);

            const detections = await faceapi
                .detectAllFaces(img)
                .withFaceLandmarks()
                .withFaceDescriptors();

            if (detections.length === 0) {
                setMatchResults(["‚ùå –õ–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"]);
                return;
            }

            // –ò—â–µ–º –ª—É—á—à–∏–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ª–∏—Ü–∞
            const results = detections.map((detection) =>
                faceMatcher.findBestMatch(detection.descriptor).toString()
            );
            if (results[0].split(' ')[0] == "unknown") {
                setMatchResults(["‚ùå –õ–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"]);
                return;
            }

            setMatchResults(results);

            // üìå –†–∏—Å—É–µ–º —Ä–∞–º–∫–∏
            const canvas = canvasRef.current;
            const imgElement = imageRef.current;
            if (!canvas || !imgElement) return;

            const ctx = canvas.getContext("2d");
            ctx.clearRect(0, 0, canvas.width, canvas.height);

            faceapi.matchDimensions(canvas, imgElement);
            const resizedDetections = faceapi.resizeResults(detections, imgElement);
            faceapi.draw.drawDetections(canvas, resizedDetections);
        } catch (e) {
            console.log(e);

        }

    };

    return (
        <div className="min-h-screen bg-gray-900 text-white flex flex-col items-center p-4">
            <h1 className="text-3xl font-bold mb-4">ü¶∏‚Äç‚ôÇÔ∏è –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ª–∏—Ü–∞</h1>

            {/* –í—ã–±–æ—Ä —Ñ–∞–π–ª–∞ */}
            <input type="file" className="mb-4 p-2 bg-gray-700 rounded" onChange={handleFileChange} />
            <button
                className="px-4 py-2 bg-blue-600 hover:bg-blue-500 rounded transition"
                onClick={recognizeFaces}
                disabled={!selectedFile}
            >
                üîç –†–∞—Å–ø–æ–∑–Ω–∞—Ç—å
            </button>

            {/* –ü—Ä–µ–≤—å—é –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è */}
            {imagePreview && (
                <div className="relative mt-6 w-85">
                    <img
                        src={imagePreview}
                        alt="Uploaded"
                        className="max-w-full rounded shadow-lg w-30px h-30px"
                        ref={imageRef}
                    />
                    <canvas
                        ref={canvasRef}
                        className="absolute top-0 left-0 w-full h-full"
                    />
                </div>
            )}

            {/* –†–µ–∑—É–ª—å—Ç–∞—Ç—ã */}
            <div className="mt-6 p-4 bg-gray-800 rounded shadow-lg w-full max-w-md">
                <h2 className="text-xl font-semibold">üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:</h2>
                <ul className="mt-2">
                    {matchResults.map((result, index) => (
                        <li key={index} className="p-2 bg-gray-700 rounded mt-1">
                            {result}
                        </li>
                    ))}
                </ul>
            </div>
        </div>
    );
}

export default FaceRecognition;
